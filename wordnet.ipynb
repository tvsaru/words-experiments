{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Do some analysis for playing English Word Games, specifically Wordle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet\n",
    "\n",
    "From  https://wn.readthedocs.io/en/latest/guides/lexicons.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[KCached file found: /Users/saru/.wn_data/downloads/cc34c0f3eb82b482b7e4ca46bce18467dd59b243\n",
      "\u001b[KSkipping oewn:2024 (Open Engish Wordnet); already added/T/tmpf_8zyqfe.xml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/saru/.wn_data/downloads/cc34c0f3eb82b482b7e4ca46bce18467dd59b243')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import wordnet\n",
    "import wn\n",
    "wn.download(\"oewn:2024\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oewn:2024\tOpen Engish Wordnet\n"
     ]
    }
   ],
   "source": [
    "for lex in wn.lexicons():\n",
    "    print(f'{lex.id}:{lex.version}\\t{lex.label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Words = 161705\n"
     ]
    }
   ],
   "source": [
    "en = wn.Wordnet(\"oewn:2024\")\n",
    "print(f\"Num Words = {len(en.words())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word('oewn--ap-hood-n'),\n",
       " Word('oewn--ap-s_Gravenhage-n'),\n",
       " Word('oewn-.22-n'),\n",
       " Word('oewn-0-n'),\n",
       " Word('oewn-1-dodecanol-n'),\n",
       " Word('oewn-1-hitter-n'),\n",
       " Word('oewn-1-n'),\n",
       " Word('oewn-10-n'),\n",
       " Word('oewn-100-n'),\n",
       " Word('oewn-1000-n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show pos(parts of speech), \"n=nous\"\n",
    "en.words(pos=\"n\")[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word('oewn-Agenise-v'),\n",
       " Word('oewn-Agenize-v'),\n",
       " Word('oewn-Americanise-v'),\n",
       " Word('oewn-Americanize-v'),\n",
       " Word('oewn-Balkanise-v'),\n",
       " Word('oewn-Balkanize-v'),\n",
       " Word('oewn-Charleston-v'),\n",
       " Word('oewn-Christianise-v'),\n",
       " Word('oewn-Christianize-v'),\n",
       " Word('oewn-DJ-v')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show pos(parts of speech), \"v=verb\"\n",
    "en.words(pos=\"v\")[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word('oewn-leaf-n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa = wn.words(\"leaf\")[0]\n",
    "wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leaf', 'leaves']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa.forms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word('oewn-leafy-a'),\n",
       " Word('oewn-leaflet-n'),\n",
       " Word('oewn-leaf-v'),\n",
       " Word('oewn-leaflet-n'),\n",
       " Word('oewn-leaf-v'),\n",
       " Word('oewn-leaf-v'),\n",
       " Word('oewn-leaflet-n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa.derived_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'hood\",\n",
       " \"'s Gravenhage\",\n",
       " \"'tween\",\n",
       " \"'tween decks\",\n",
       " '.22-caliber',\n",
       " '.22-calibre',\n",
       " '.22',\n",
       " '.22 caliber',\n",
       " '.22 calibre',\n",
       " '.38-caliber']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [wf  for w in wn.words() for wf in w.forms()]\n",
    "words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wfns length = 76399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aalii',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aardwolves',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abaca']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = \"^[a-z]+$\"\n",
    "wfns = [w for w in words if re.match(pattern, w)]\n",
    "print(f\"wfns length = {len(wfns)}\")\n",
    "\n",
    "wfns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five letter words frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five letters word length = 4356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['uncut',\n",
       " 'hymen',\n",
       " 'ponce',\n",
       " 'glans',\n",
       " 'click',\n",
       " 'flung',\n",
       " 'intro',\n",
       " 'liven',\n",
       " 'wrack',\n",
       " 'gonia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivew = {w for w in wfns if len(w) == 5}\n",
    "print(f\"five letters word length = {len(fivew)}\")\n",
    "list(fivew)[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict, Counter\n",
    "counter_start = Counter()\n",
    "counter_all = Counter()\n",
    "for w in fivew:\n",
    "    counter_start.update([w[0]])\n",
    "    counter_all.update(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N starting alphabet - in 5 letter words\n",
      "\n",
      "\ts\t590\n",
      "\tc\t355\n",
      "\tb\t333\n",
      "\tp\t290\n",
      "\ta\t290\n",
      "\tt\t283\n",
      "\tm\t230\n",
      "\tf\t219\n",
      "\td\t199\n",
      "\tg\t198\n",
      "\tl\t196\n",
      "\tr\t190\n",
      "\th\t139\n",
      "\tw\t124\n",
      "\te\t119\n",
      "\tn\t95\n",
      "\to\t91\n",
      "\tv\t81\n",
      "\tk\t75\n",
      "\ti\t67\n",
      "\tu\t58\n",
      "\tj\t50\n",
      "\tq\t35\n",
      "\ty\t19\n",
      "\tz\t15\n",
      "\tx\t15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top N starting alphabet - in 5 letter words\\n\")\n",
    "for (alpha, cnt) in counter_start.most_common(26):\n",
    "    print(f\"\\t{alpha}\\t{cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N alphabet - in 5 letter words\n",
      "\n",
      "\te\t2225\n",
      "\ta\t2067\n",
      "\tr\t1544\n",
      "\to\t1459\n",
      "\ti\t1412\n",
      "\ts\t1295\n",
      "\tl\t1279\n",
      "\tt\t1230\n",
      "\tn\t1104\n",
      "\tu\t885\n",
      "\tc\t839\n",
      "\ty\t783\n",
      "\td\t747\n",
      "\tp\t725\n",
      "\tm\t690\n",
      "\th\t640\n",
      "\tg\t552\n",
      "\tb\t551\n",
      "\tk\t402\n",
      "\tf\t378\n",
      "\tw\t316\n",
      "\tv\t283\n",
      "\tx\t142\n",
      "\tz\t108\n",
      "\tj\t72\n",
      "\tq\t52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top N alphabet - in 5 letter words\\n\")\n",
    "for (alpha, cnt) in counter_all.most_common(26):\n",
    "    print(f\"\\t{alpha}\\t{cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaca\tWordStats(has_repeated_chars=True, unique_chars={'c', 'b', 'a'}, unique_vowels={'a'}, all_vowels=['a', 'a', 'a'])\n",
      "piano\tWordStats(has_repeated_chars=False, unique_chars={'a', 'p', 'n', 'i', 'o'}, unique_vowels={'i', 'o', 'a'}, all_vowels=['i', 'a', 'o'])\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "vowels = {\"a\", \"e\", \"i\", \"o\", \"u\"}\n",
    "\n",
    "@dataclass\n",
    "class WordStats():\n",
    "    has_repeated_chars : bool\n",
    "    unique_chars : set[chr]\n",
    "    unique_vowels : set[chr]\n",
    "    all_vowels: list[chr]\n",
    "\n",
    "    def __init__(self, word):\n",
    "        c = Counter(word)\n",
    "        self.has_repeated_chars = len(c.items()) != len(word)\n",
    "        self.unique_chars = set(c)\n",
    "        self.unique_vowels = self.unique_chars & vowels\n",
    "        self.all_vowels = [e for e in c.elements() if e in vowels]\n",
    "\n",
    "test_words = [\"abaca\", \"piano\"]\n",
    "for tw in test_words:\n",
    "    ws = WordStats(tw)\n",
    "    print(f\"{tw}\\t{ws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file output/wordnet-5-letter-words-unique.tsv\n",
      "Writing to file output/wordnet-5-letter-words-all-senses.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def export_words_with_info(words, fname):\n",
    "    path = f\"output/{fname}-unique.tsv\"\n",
    "    print(f\"Writing to file {path}\")\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(f\"word\\tws.reps\\tws.uniq_chars\\tuniq_vowels\\tdup_vowels\\tpos\\tss\\tdefinition\\n\")\n",
    "        for w in sorted(words):\n",
    "            stats = WordStats(w)\n",
    "            ss_set = en.synsets(w)\n",
    "            ss = ss_set[0]\n",
    "            f.write(f\"{w}\\treps:{stats.has_repeated_chars}\\tuc:{len(stats.unique_chars)}\\tuv:{len(stats.unique_vowels)}\\tdv:{len(stats.all_vowels)-len(stats.unique_vowels)}\\t{ss.pos}\\t{len(ss_set)}\\t{ss.definition()}\\n\")\n",
    "\n",
    "    path = f\"output/{fname}-all-senses.tsv\"\n",
    "    print(f\"Writing to file {path}\")\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(f\"word\\tpos\\tss:n\\tdefinition\\n\")\n",
    "        for w in sorted(words):\n",
    "            ss_set = en.synsets(w)\n",
    "            l_ss_set= len(ss_set)\n",
    "            for i,ss in enumerate(ss_set, start=1):\n",
    "                f.write(f\"{w}\\t{ss.pos}\\t{l_ss_set}:{i}\\t{ss.definition()}\\n\")\n",
    "\n",
    "\n",
    "export_words_with_info(fivew, \"wordnet-5-letter-words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
